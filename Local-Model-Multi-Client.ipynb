{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fT7VJsW98eNlziThRrd9sHcjPMDKRIc9","timestamp":1714340393936}],"authorship_tag":"ABX9TyOFeumNPRcIZVjLo+XHQrFC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"abpOWHPT3hNL","executionInfo":{"status":"ok","timestamp":1714340576936,"user_tz":240,"elapsed":19654,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}}},"outputs":[],"source":["import torch\n","from torchvision.datasets import MNIST\n","from torch.utils.data import random_split, DataLoader\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","\n","import pickle\n","import base64\n","import sys\n","\n","import hashlib\n","import json\n","from time import time\n","from time import sleep\n","import requests\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = [5, 5]"]},{"cell_type":"code","source":["train_dataset = MNIST('/kaggle/working', train=True, download=True, transform=transforms.ToTensor())\n","test_dataset = MNIST('/kaggle/working', train=False, download=True, transform=transforms.ToTensor())\n","\n","train_dataset, dev_dataset = random_split(train_dataset, [int(len(train_dataset) * 0.83), int(len(train_dataset) * 0.17)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ZnMuR0B3mm3","executionInfo":{"status":"ok","timestamp":1714340869143,"user_tz":240,"elapsed":283390,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}},"outputId":"745dc417-03f8-4f2f-bdf8-271bd3cb0ba7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /kaggle/working/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [04:41<00:00, 35222.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /kaggle/working/MNIST/raw/train-images-idx3-ubyte.gz to /kaggle/working/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /kaggle/working/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 937024.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /kaggle/working/MNIST/raw/train-labels-idx1-ubyte.gz to /kaggle/working/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /kaggle/working/MNIST/raw/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 503: Service Unavailable\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /kaggle/working/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 9788296.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /kaggle/working/MNIST/raw/t10k-images-idx3-ubyte.gz to /kaggle/working/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /kaggle/working/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 10214760.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /kaggle/working/MNIST/raw/t10k-labels-idx1-ubyte.gz to /kaggle/working/MNIST/raw\n","\n"]}]},{"cell_type":"code","source":["total_train_size = len(train_dataset)\n","total_test_size = len(test_dataset)\n","total_dev_size = len(dev_dataset)\n","\n","classes = 10\n","input_dim = 784\n","\n","batch_size = 128\n","epochs_per_client = 3\n","learning_rate = 2e-2"],"metadata":{"id":"DX0sjIoO3s3l","executionInfo":{"status":"ok","timestamp":1714340883348,"user_tz":240,"elapsed":102,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# CONFIGURE BEFORE RUNNIG\n","# MAKE SURE SAME FOR BOTH SERVER AND ALL CLIENTS' CODE\n","num_clients = 2\n","rounds = 1"],"metadata":{"id":"EJ9nYwFv33N6","executionInfo":{"status":"ok","timestamp":1714341178283,"user_tz":240,"elapsed":116,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# CONFIGURE CLIENT ID TO CONTAIN ALL POSSIBLE CLIENT IDs\n","# Ex. If there are 3 clients, the only possible client ids are 0, 1, 2\n","# The client_id variable will therefore be equal to [0,1,2]\n","client_id = [0,1]"],"metadata":{"id":"20LYeX8hScnv","executionInfo":{"status":"ok","timestamp":1714340888759,"user_tz":240,"elapsed":99,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["client_code = [f'L{client_id[i]+1}' for i in client_id]"],"metadata":{"id":"Vj6eu5x5SiYM","executionInfo":{"status":"ok","timestamp":1714340890272,"user_tz":240,"elapsed":119,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["CHAIN_URL = 'https://2347b804-83c2-481a-9697-c5f6de62b5ab-00-2qo920vvfssrt.spock.replit.dev/chain'\n","MINE_URL = 'https://2347b804-83c2-481a-9697-c5f6de62b5ab-00-2qo920vvfssrt.spock.replit.dev/mine'\n","SEND_TRNS_URL = 'https://2347b804-83c2-481a-9697-c5f6de62b5ab-00-2qo920vvfssrt.spock.replit.dev/transactions/new'\n","GET_TRNS_URL = 'https://2347b804-83c2-481a-9697-c5f6de62b5ab-00-2qo920vvfssrt.spock.replit.dev/current'\n","PREV_BLK_URL = 'https://2347b804-83c2-481a-9697-c5f6de62b5ab-00-2qo920vvfssrt.spock.replit.dev/last'"],"metadata":{"id":"UgWcuAfe35T0","executionInfo":{"status":"ok","timestamp":1714340902954,"user_tz":240,"elapsed":112,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["total_train_size, total_dev_size, total_test_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UXTPJc8k359T","executionInfo":{"status":"ok","timestamp":1714340905753,"user_tz":240,"elapsed":402,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}},"outputId":"a25127a4-261d-4ca5-9e80-9a7f8eb114c5"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(49800, 10200, 10000)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["def get_device():\n","    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","def to_device(data, device):\n","    if isinstance(data, (list, tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader(DataLoader):\n","        def __init__(self, dl, device):\n","            self.dl = dl\n","            self.device = device\n","\n","        def __iter__(self):\n","            for batch in self.dl:\n","                yield to_device(batch, self.device)\n","\n","        def __len__(self):\n","            return len(self.dl)\n","\n","device = get_device()"],"metadata":{"id":"Tz8uxvM7396u","executionInfo":{"status":"ok","timestamp":1714340908385,"user_tz":240,"elapsed":107,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class FederatedNet(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = torch.nn.Conv2d(1, 20, 7)\n","        self.conv2 = torch.nn.Conv2d(20, 40, 7)\n","        self.maxpool = torch.nn.MaxPool2d(2, 2)\n","        self.flatten = torch.nn.Flatten()\n","        self.linear = torch.nn.Linear(2560, 10)\n","        self.non_linearity = torch.nn.functional.relu\n","        self.track_layers = {'conv1': self.conv1, 'conv2': self.conv2, 'linear': self.linear}\n","\n","    def forward(self, x_batch):\n","        out = self.conv1(x_batch)\n","        out = self.non_linearity(out)\n","        out = self.conv2(out)\n","        out = self.non_linearity(out)\n","        out = self.maxpool(out)\n","        out = self.flatten(out)\n","        out = self.linear(out)\n","        return out\n","\n","    def get_track_layers(self):\n","        return self.track_layers\n","\n","    def apply_parameters(self, parameters_dict):\n","        with torch.no_grad():\n","            for layer_name in parameters_dict:\n","                self.track_layers[layer_name].weight.data *= 0\n","                self.track_layers[layer_name].bias.data *= 0\n","                self.track_layers[layer_name].weight.data += parameters_dict[layer_name]['weight']\n","                self.track_layers[layer_name].bias.data += parameters_dict[layer_name]['bias']\n","\n","    def get_parameters(self):\n","        parameters_dict = dict()\n","        for layer_name in self.track_layers:\n","            parameters_dict[layer_name] = {\n","                'weight': self.track_layers[layer_name].weight.data,\n","                'bias': self.track_layers[layer_name].bias.data\n","            }\n","        return parameters_dict\n","\n","    def batch_accuracy(self, outputs, labels):\n","        with torch.no_grad():\n","            _, predictions = torch.max(outputs, dim=1)\n","            return torch.tensor(torch.sum(predictions == labels).item() / len(predictions))\n","\n","    def _process_batch(self, batch):\n","        images, labels = batch\n","        outputs = self(images)\n","        loss = torch.nn.functional.cross_entropy(outputs, labels)\n","        accuracy = self.batch_accuracy(outputs, labels)\n","        return (loss, accuracy)\n","\n","    def fit(self, dataset, epochs, lr, batch_size=128, opt=torch.optim.SGD):\n","        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size, shuffle=True), device)\n","        optimizer = opt(self.parameters(), lr)\n","        history = []\n","        for epoch in range(epochs):\n","            losses = []\n","            accs = []\n","            for batch in dataloader:\n","                loss, acc = self._process_batch(batch)\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","                loss.detach()\n","                losses.append(loss)\n","                accs.append(acc)\n","            avg_loss = torch.stack(losses).mean().item()\n","            avg_acc = torch.stack(accs).mean().item()\n","            history.append((avg_loss, avg_acc))\n","        return history\n","\n","    def evaluate(self, dataset, batch_size=128):\n","        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size), device)\n","        losses = []\n","        accs = []\n","        with torch.no_grad():\n","            for batch in dataloader:\n","                loss, acc = self._process_batch(batch)\n","                losses.append(loss)\n","                accs.append(acc)\n","        avg_loss = torch.stack(losses).mean().item()\n","        avg_acc = torch.stack(accs).mean().item()\n","        return (avg_loss, avg_acc)"],"metadata":{"id":"I0o4uFFz3-VH","executionInfo":{"status":"ok","timestamp":1714340910509,"user_tz":240,"elapsed":110,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class Client:\n","    def __init__(self, client_id, dataset):\n","        self.client_id = client_id\n","        self.dataset = dataset\n","\n","    def get_dataset_size(self):\n","        return len(self.dataset)\n","\n","    def get_client_id(self):\n","        return self.client_id\n","\n","    def train(self, parameters_dict):\n","        net = to_device(FederatedNet(), device)\n","        net.apply_parameters(parameters_dict)\n","        train_history = net.fit(self.dataset, epochs_per_client, learning_rate, batch_size)\n","        print('{}: Loss = {}, Accuracy = {}'.format(self.client_id, round(train_history[-1][0], 4), round(train_history[-1][1], 4)))\n","        return net.get_parameters()"],"metadata":{"id":"EEL4Btdb4BhH","executionInfo":{"status":"ok","timestamp":1714340914835,"user_tz":240,"elapsed":334,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def compress_params(params):\n","  compressed = pickle.dumps(params)\n","  params_bytes = base64.b64encode(compressed)\n","  params_bystr = params_bytes.decode('ascii')\n","  return params_bystr\n","\n","def decompress_params(params):\n","  decompressed = params.encode(\"ascii\")\n","  decompressed = base64.b64decode(decompressed)\n","  decompressed = pickle.loads(decompressed)\n","  return decompressed"],"metadata":{"id":"UJbe0ncV4D5j","executionInfo":{"status":"ok","timestamp":1714340916333,"user_tz":240,"elapsed":130,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["examples_per_client = total_train_size // num_clients\n","client_datasets = random_split(train_dataset, [min(i + examples_per_client,\n","           total_train_size) - i for i in range(0, total_train_size, examples_per_client)])\n","clients = [Client('client_' + str(i), client_datasets[i]) for i in range(num_clients)]"],"metadata":{"id":"caNXOZBD4F6L","executionInfo":{"status":"ok","timestamp":1714340920721,"user_tz":240,"elapsed":133,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["prev_block_index = None\n","for i in range(rounds):\n","  response = requests.get(PREV_BLK_URL)\n","  block_index = response.json()['chain']['index']\n","\n","  if i == 0:\n","    prev_block_index = block_index\n","\n","  new_block = True if prev_block_index != block_index else False\n","  while response.json()['chain']['transactions'][-2]['type'] != 'global' and not new_block:\n","    sleep(45)\n","    response = requests.get(PREV_BLK_URL)\n","\n","  prev_block_index = block_index\n","\n","  curr_global_gradients = response.json()['chain']['transactions'][-2]['gradients']\n","  curr_global_gradients = decompress_params(curr_global_gradients)\n","\n","  for j in client_id:\n","    client_parameters = clients[j].train(curr_global_gradients)\n","    client_data_size = clients[j].get_dataset_size()\n","    client_parameters_compressed = compress_params(client_parameters)\n","    new_transaction = {\n","        'type': 'local',\n","        'trainer': client_code[j],\n","        'gradient': client_parameters_compressed,\n","        'data-size': client_data_size\n","    }\n","\n","    # Send the transaction to the server\n","    response = requests.post(SEND_TRNS_URL, json=new_transaction)\n","    print(response.json())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"daWNgm9bOjLT","executionInfo":{"status":"ok","timestamp":1714341808384,"user_tz":240,"elapsed":356900,"user":{"displayName":"Jawad Rahman","userId":"04762065149889573479"}},"outputId":"37a77869-da54-4e62-ef2f-8632556e9daf"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["client_0: Loss = 0.2074, Accuracy = 0.9411\n","{'message': 'Transaction will be added to Block 3'}\n","client_1: Loss = 0.2047, Accuracy = 0.9395\n","{'message': 'Transaction will be added to Block 3'}\n"]}]}]}