{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "abpOWHPT3hNL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "import base64\n",
        "import sys\n",
        "\n",
        "import hashlib\n",
        "import json\n",
        "from time import time\n",
        "from time import sleep\n",
        "import requests\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [5, 5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEF9y4ARFLtl",
        "outputId": "78c59ec5-f8c2-49ae-fa34-f9f6ed744024"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torchmetrics-1.4.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import tensor\n",
        "from torchmetrics.classification import MulticlassRecall\n",
        "from torchmetrics.classification import MulticlassPrecision"
      ],
      "metadata": {
        "id": "1olBKGwtFOKZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xddZgxb6fBlP",
        "outputId": "de48586f-1aee-4431-b7cf-4992f079aefc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = 10\n",
        "input_dim = 784\n",
        "\n",
        "batch_size = 128\n",
        "epochs_per_client = 3\n",
        "learning_rate = 2e-2"
      ],
      "metadata": {
        "id": "DX0sjIoO3s3l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURE BEFORE RUNNIG\n",
        "# MAKE SURE SAME FOR BOTH SERVER AND ALL CLIENTS' CODE\n",
        "num_clients = 2\n",
        "rounds = 2"
      ],
      "metadata": {
        "id": "EJ9nYwFv33N6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURE CLIENT ID TO CONTAIN ALL POSSIBLE CLIENT IDs\n",
        "# Ex. If there are 3 clients, the only possible client ids are 0, 1, 2\n",
        "# The client_id variable will therefore be equal to [0,1,2]\n",
        "client_id = [0,1]"
      ],
      "metadata": {
        "id": "20LYeX8hScnv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_code = [f'L{client_id[i]+1}' for i in client_id]"
      ],
      "metadata": {
        "id": "Vj6eu5x5SiYM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure there is no '/' at the end of the url.\n",
        "replit_url = \"https://8e7399ac-6fda-47b4-9b7b-e7a2ed8d5bf1-00-1vdkonhfb818n.riker.replit.dev\"\n",
        "\n",
        "CHAIN_URL = f'{replit_url}/chain'\n",
        "MINE_URL = f'{replit_url}/mine'\n",
        "SEND_TRNS_URL = f'{replit_url}/transactions/new'\n",
        "GET_TRNS_URL = f'{replit_url}/current'\n",
        "PREV_BLK_URL = f'{replit_url}/last'"
      ],
      "metadata": {
        "id": "UgWcuAfe35T0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader(DataLoader):\n",
        "        def __init__(self, dl, device):\n",
        "            self.dl = dl\n",
        "            self.device = device\n",
        "\n",
        "        def __iter__(self):\n",
        "            for batch in self.dl:\n",
        "                yield to_device(batch, self.device)\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.dl)\n",
        "\n",
        "device = get_device()"
      ],
      "metadata": {
        "id": "Tz8uxvM7396u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FederatedNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 20, 7)\n",
        "        self.conv2 = torch.nn.Conv2d(20, 40, 7)\n",
        "        self.maxpool = torch.nn.MaxPool2d(2, 2)\n",
        "        self.flatten = torch.nn.Flatten()\n",
        "        self.linear = torch.nn.Linear(2560, 10)\n",
        "        self.non_linearity = torch.nn.functional.relu\n",
        "        self.track_layers = {'conv1': self.conv1, 'conv2': self.conv2, 'linear': self.linear}\n",
        "\n",
        "    def forward(self, x_batch):\n",
        "        out = self.conv1(x_batch)\n",
        "        out = self.non_linearity(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.non_linearity(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.flatten(out)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "    def get_track_layers(self):\n",
        "        return self.track_layers\n",
        "\n",
        "    def apply_parameters(self, parameters_dict):\n",
        "        with torch.no_grad():\n",
        "            for layer_name in parameters_dict:\n",
        "                self.track_layers[layer_name].weight.data *= 0\n",
        "                self.track_layers[layer_name].bias.data *= 0\n",
        "                self.track_layers[layer_name].weight.data += parameters_dict[layer_name]['weight']\n",
        "                self.track_layers[layer_name].bias.data += parameters_dict[layer_name]['bias']\n",
        "\n",
        "    def get_parameters(self):\n",
        "        parameters_dict = dict()\n",
        "        for layer_name in self.track_layers:\n",
        "            parameters_dict[layer_name] = {\n",
        "                'weight': self.track_layers[layer_name].weight.data,\n",
        "                'bias': self.track_layers[layer_name].bias.data\n",
        "            }\n",
        "        return parameters_dict\n",
        "\n",
        "    def batch_accuracy(self, outputs, labels):\n",
        "        with torch.no_grad():\n",
        "            _, predictions = torch.max(outputs, dim=1)\n",
        "            return torch.tensor(torch.sum(predictions == labels).item() / len(predictions))\n",
        "\n",
        "    def _process_batch(self, batch):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
        "        accuracy = self.batch_accuracy(outputs, labels)\n",
        "        precision = MulticlassPrecision(num_classes=10).to(device)\n",
        "        precision_score = precision(outputs, labels)\n",
        "        recall = MulticlassRecall(num_classes=10).to(device)\n",
        "        recall_score = recall(outputs, labels)\n",
        "        return (loss, accuracy, precision_score, recall_score)\n",
        "\n",
        "    def fit(self, dataset, epochs, lr, batch_size=128, opt=torch.optim.SGD):\n",
        "        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size, shuffle=True), device)\n",
        "        optimizer = opt(self.parameters(), lr)\n",
        "        history = []\n",
        "        for epoch in range(epochs):\n",
        "            losses = []\n",
        "            accs = []\n",
        "            prec_list = []\n",
        "            rec_list = []\n",
        "            for batch in dataloader:\n",
        "                loss, acc, prec, rec = self._process_batch(batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                loss.detach()\n",
        "                losses.append(loss)\n",
        "                accs.append(acc)\n",
        "                prec_list.append(prec)\n",
        "                rec_list.append(rec)\n",
        "            avg_loss = torch.stack(losses).mean().item()\n",
        "            avg_acc = torch.stack(accs).mean().item()\n",
        "            avg_prec = torch.stack(prec_list).mean().item()\n",
        "            avg_rec = torch.stack(rec_list).mean().item()\n",
        "            f1 = (2*avg_prec*avg_rec) / (avg_prec + avg_rec)\n",
        "            history.append((avg_loss, avg_acc, avg_prec, avg_rec, f1))\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, dataset, batch_size=128):\n",
        "        dataloader = DeviceDataLoader(DataLoader(dataset, batch_size), device)\n",
        "        losses = []\n",
        "        accs = []\n",
        "        prec_list = []\n",
        "        rec_list = []\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                loss, acc, prec, rec = self._process_batch(batch)\n",
        "                losses.append(loss)\n",
        "                accs.append(acc)\n",
        "                prec_list.append(prec)\n",
        "                rec_list.append(rec)\n",
        "        avg_loss = torch.stack(losses).mean().item()\n",
        "        avg_acc = torch.stack(accs).mean().item()\n",
        "        avg_prec = torch.stack(prec_list).mean().item()\n",
        "        avg_rec = torch.stack(rec_list).mean().item()\n",
        "        f1 = (2*avg_prec*avg_rec) / (avg_prec + avg_rec)\n",
        "        return (avg_loss, avg_acc, avg_prec, avg_rec, f1)"
      ],
      "metadata": {
        "id": "I0o4uFFz3-VH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Client:\n",
        "    def __init__(self, client_id, dataset):\n",
        "        self.client_id = client_id\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def get_dataset_size(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def get_client_id(self):\n",
        "        return self.client_id\n",
        "\n",
        "    def train(self, parameters_dict):\n",
        "        net = to_device(FederatedNet(), device)\n",
        "        net.apply_parameters(parameters_dict)\n",
        "        train_history = net.fit(self.dataset, epochs_per_client, learning_rate, batch_size)\n",
        "        print('{}: Loss = {}, Accuracy = {}, Precision = {}, Recall = {}, F1 = {}'.format(self.client_id, round(train_history[-1][0], 4), round(train_history[-1][1], 4), round(train_history[-1][2], 4), round(train_history[-1][3], 4), round(train_history[-1][4], 4)))\n",
        "        return net.get_parameters()"
      ],
      "metadata": {
        "id": "EEL4Btdb4BhH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compress_params(params):\n",
        "  compressed = pickle.dumps(params)\n",
        "  params_bytes = base64.b64encode(compressed)\n",
        "  params_bystr = params_bytes.decode('ascii')\n",
        "  return params_bystr\n",
        "\n",
        "def decompress_params(params):\n",
        "  decompressed = params.encode(\"ascii\")\n",
        "  decompressed = base64.b64decode(decompressed)\n",
        "  decompressed = pickle.loads(decompressed)\n",
        "  return decompressed"
      ],
      "metadata": {
        "id": "UJbe0ncV4D5j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_datasets = []\n",
        "\n",
        "for i in range(8):\n",
        "  with open(f'/content/gdrive/MyDrive/Colab Notebooks/BC+FL Code/datasets/client_train_set_{i}.pickle', 'rb') as fp:\n",
        "    client_datasets.append(pickle.load(fp))"
      ],
      "metadata": {
        "id": "caNXOZBD4F6L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clients = []\n",
        "\n",
        "for i in client_id:\n",
        "  client_dataset = None\n",
        "  if int(8 / num_clients == 1):\n",
        "    client_dataset = client_datasets[client_id]\n",
        "  else:\n",
        "    sets_per_client = int(8 / num_clients)\n",
        "    # for i in range(sets_per_client):\n",
        "    #   print(sets_per_client * client_id + i)\n",
        "    start = sets_per_client * client_id[i]\n",
        "    end = sets_per_client * client_id[i] + sets_per_client\n",
        "    client_dataset = torch.utils.data.ConcatDataset(client_datasets[start:end])\n",
        "  clients.append(Client('client_' + str(i), client_dataset))"
      ],
      "metadata": {
        "id": "qqtUfKtnfPMg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_block_index = -1\n",
        "for i in range(rounds):\n",
        "  response = requests.get(PREV_BLK_URL)\n",
        "  block_index = response.json()['chain']['index']\n",
        "\n",
        "  # print(prev_block_index)\n",
        "  # print(block_index)\n",
        "\n",
        "  # if i == 0:\n",
        "  #   prev_block_index = block_index\n",
        "\n",
        "  # print(prev_block_index)\n",
        "\n",
        "  new_block = False if int(prev_block_index) == int(block_index) else True\n",
        "  # print(new_block)\n",
        "  # print(response.json()['chain']['transactions'][-2]['type'] != 'global')\n",
        "  cond = response.json()['chain']['transactions'][-2]['type'] != 'global' or new_block == False\n",
        "  print(cond)\n",
        "\n",
        "  while response.json()['chain']['transactions'][-2]['type'] != 'global' or new_block == False:\n",
        "    sleep(30)\n",
        "    response = requests.get(PREV_BLK_URL)\n",
        "    block_index = response.json()['chain']['index']\n",
        "    new_block = False if int(prev_block_index) == int(block_index) else True\n",
        "    print(cond)\n",
        "\n",
        "  prev_block_index = block_index\n",
        "\n",
        "  curr_global_gradients = response.json()['chain']['transactions'][-2]['gradients']\n",
        "  curr_global_gradients = decompress_params(curr_global_gradients)\n",
        "\n",
        "  for layer_name in curr_global_gradients:\n",
        "    curr_global_gradients[layer_name]['weight'] = curr_global_gradients[layer_name]['weight'].to(device)\n",
        "    curr_global_gradients[layer_name]['bias'] = curr_global_gradients[layer_name]['bias'].to(device)\n",
        "\n",
        "  for j in client_id:\n",
        "    sleep(5)\n",
        "    client_parameters = clients[j].train(curr_global_gradients)\n",
        "\n",
        "    for layer_name in client_parameters:\n",
        "      client_parameters[layer_name]['weight'] = client_parameters[layer_name]['weight'].to('cpu')\n",
        "      client_parameters[layer_name]['bias'] = client_parameters[layer_name]['bias'].to('cpu')\n",
        "\n",
        "    client_data_size = clients[j].get_dataset_size()\n",
        "    client_parameters_compressed = compress_params(client_parameters)\n",
        "    new_transaction = {\n",
        "        'type': 'local',\n",
        "        'trainer': client_code[j],\n",
        "        'gradient': client_parameters_compressed,\n",
        "        'data-size': client_data_size\n",
        "    }\n",
        "\n",
        "    # Send the transaction to the server\n",
        "    response = requests.post(SEND_TRNS_URL, json=new_transaction)\n",
        "    print(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daWNgm9bOjLT",
        "outputId": "65d66be6-eef8-4b6e-98af-c97577f1a78a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "client_0: Loss = 0.1993, Accuracy = 0.9409, Precision = 0.9413, Recall = 0.9407, F1 = 0.941\n",
            "{'message': 'Transaction will be added to Block 3'}\n",
            "client_1: Loss = 0.2044, Accuracy = 0.9422, Precision = 0.9433, Recall = 0.9421, F1 = 0.9427\n",
            "{'message': 'Transaction will be added to Block 3'}\n",
            "True\n",
            "True\n",
            "client_0: Loss = 0.1125, Accuracy = 0.9674, Precision = 0.9676, Recall = 0.9673, F1 = 0.9675\n",
            "{'message': 'Transaction will be added to Block 5'}\n",
            "client_1: Loss = 0.1131, Accuracy = 0.9669, Precision = 0.9669, Recall = 0.9666, F1 = 0.9668\n",
            "{'message': 'Transaction will be added to Block 5'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yiPWa5yHU_n",
        "outputId": "1b0bc167-ea50-41fe-82c7-8687afbb7834"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [201]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_net = to_device(FederatedNet(), 'cpu')\n",
        "curr_parameters = global_net.get_parameters()\n",
        "\n",
        "for layer_name in curr_parameters:\n",
        "    curr_parameters[layer_name]['weight'] = curr_parameters[layer_name]['weight'].to(device)\n",
        "    curr_parameters[layer_name]['bias'] = curr_parameters[layer_name]['bias'].to(device)\n",
        "\n",
        "for j in client_id:\n",
        "  #clients[j].to(device)\n",
        "  client_parameters = clients[j].train(curr_parameters)\n",
        "  client_data_size = clients[j].get_dataset_size()\n",
        "  print(client_data_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSQymMuQh7hI",
        "outputId": "655a7c39-7fe4-43bc-954a-d5d6298b1fbb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client_0: Loss = 0.1968, Accuracy = 0.9422, Precision = 0.9422, Recall = 0.9415, F1 = 0.9419\n",
            "24900\n",
            "client_1: Loss = 0.2031, Accuracy = 0.9416, Precision = 0.9428, Recall = 0.9407, F1 = 0.9417\n",
            "24900\n"
          ]
        }
      ]
    }
  ]
}